
# Leibniz: A Rewriting System for Expressions

Author:	Anthony John Ripa

Date:	2022.04.20

Live Demo of Version  1 at <a href='https://swish.swi-prolog.org/p/hVEWFHXN.pl'>https://swish.swi-prolog.org/p/hVEWFHXN.pl</a>

Live Demo of Version  2 at <a href='https://swish.swi-prolog.org/p/JWdsRkzO.pl'>https://swish.swi-prolog.org/p/JWdsRkzO.pl</a>

Live Demo of Version  3 at <a href='https://swish.swi-prolog.org/p/fMJuWNsH.pl'>https://swish.swi-prolog.org/p/fMJuWNsH.pl</a>

Live Demo of Version  4 at <a href='https://swish.swi-prolog.org/p/oeuNtQbk.pl'>https://swish.swi-prolog.org/p/oeuNtQbk.pl</a>

Live Demo of Version  5 at <a href='https://swish.swi-prolog.org/p/txPnJtvm.pl'>https://swish.swi-prolog.org/p/txPnJtvm.pl</a>

Live Demo of Version  6 at <a href='https://swish.swi-prolog.org/p/zhOrBjYr.pl'>https://swish.swi-prolog.org/p/zhOrBjYr.pl</a>

Live Demo of Version  7 at <a href='https://swish.swi-prolog.org/p/XLCwOknT.pl'>https://swish.swi-prolog.org/p/XLCwOknT.pl</a>

Live Demo of Version  8 at <a href='https://swish.swi-prolog.org/p/nTiEvFQq.pl'>https://swish.swi-prolog.org/p/nTiEvFQq.pl</a>

Live Demo of Version  9 at <a href='https://swish.swi-prolog.org/p/bDaiBkLV.pl'>https://swish.swi-prolog.org/p/bDaiBkLV.pl</a>

Live Demo of Version 10 at <a href='https://swish.swi-prolog.org/p/EuEYjSIE.pl'>https://swish.swi-prolog.org/p/EuEYjSIE.pl</a>

Live Demo of Version 11 at <a href='https://swish.swi-prolog.org/p/BmSRzUaV.pl'>https://swish.swi-prolog.org/p/BmSRzUaV.pl</a>

Live Demo of Version 12 at <a href='https://swish.swi-prolog.org/p/jBWdZyZS.pl'>https://swish.swi-prolog.org/p/jBWdZyZS.pl</a>

Live Demo of Version 13 at <a href='https://swish.swi-prolog.org/p/XKwSQIHP.pl'>https://swish.swi-prolog.org/p/XKwSQIHP.pl</a>

Live Demo of Version 14 at <a href='https://swish.swi-prolog.org/p/FrxKkJXa.pl'>https://swish.swi-prolog.org/p/FrxKkJXa.pl</a>

Live Demo of Version 15 at <a href='https://swish.swi-prolog.org/p/lbjsQXIh.pl'>https://swish.swi-prolog.org/p/lbjsQXIh.pl</a>

Live Demo of Version 16 at <a href='https://swish.swi-prolog.org/p/GSfUPNft.pl'>https://swish.swi-prolog.org/p/GSfUPNft.pl</a>

Live Demo of Version 17 at <a href='https://swish.swi-prolog.org/p/dRcCftbI.pl'>https://swish.swi-prolog.org/p/dRcCftbI.pl</a>

Live Demo of Version 18 at <a href='https://swish.swi-prolog.org/p/oJwKjMry.pl'>https://swish.swi-prolog.org/p/oJwKjMry.pl</a>

Live Demo of Version 19 at <a href='https://swish.swi-prolog.org/p/lltCdZLR.pl'>https://swish.swi-prolog.org/p/lltCdZLR.pl</a>

Live Demo of Version 20 at <a href='https://swish.swi-prolog.org/p/DEKeboal.pl'>https://swish.swi-prolog.org/p/DEKeboal.pl</a>

Live Demo of Version 21 at <a href='https://swish.swi-prolog.org/p/KAPHrSTb.pl'>https://swish.swi-prolog.org/p/KAPHrSTb.pl</a>

Live Demo of Version 22 at <a href='https://swish.swi-prolog.org/p/KyEsVtPj.pl'>https://swish.swi-prolog.org/p/KyEsVtPj.pl</a>

Live Demo of Version 23 at <a href='https://swish.swi-prolog.org/p/ywXZGtSr.pl'>https://swish.swi-prolog.org/p/ywXZGtSr.pl</a>

Live Demo of Version 24 at <a href='https://swish.swi-prolog.org/p/nLRXyBmQ.pl'>https://swish.swi-prolog.org/p/nLRXyBmQ.pl</a>

Live Demo of Version 25 at <a href='https://swish.swi-prolog.org/p/vERRvwXC.pl'>https://swish.swi-prolog.org/p/vERRvwXC.pl</a>

Live Demo of Version 26 at <a href='https://swish.swi-prolog.org/p/YnEhbMPB.pl'>https://swish.swi-prolog.org/p/YnEhbMPB.pl</a>

Live Demo of Version 27 at <a href='https://swish.swi-prolog.org/p/VYojppKx.pl'>https://swish.swi-prolog.org/p/VYojppKx.pl</a>

Live Demo of Version 28 at <a href='https://swish.swi-prolog.org/p/EoLuOJTT.pl'>https://swish.swi-prolog.org/p/EoLuOJTT.pl</a>

Live Demo of Version 29 at <a href='https://swish.swi-prolog.org/p/vxZoBHOU.pl'>https://swish.swi-prolog.org/p/vxZoBHOU.pl</a>

Live Demo of Version 30 at <a href='https://swish.swi-prolog.org/p/fKEQsrdU.pl'>https://swish.swi-prolog.org/p/fKEQsrdU.pl</a>

Live Demo of Version 31 at <a href='https://swish.swi-prolog.org/p/cAhQaWug.pl'>https://swish.swi-prolog.org/p/cAhQaWug.pl</a>

Live Demo of Version 32 at <a href='https://swish.swi-prolog.org/p/phGOgCOY.pl'>https://swish.swi-prolog.org/p/phGOgCOY.pl</a>

Live Demo of Version 33 at <a href='https://swish.swi-prolog.org/p/PriFIpMa.pl'>https://swish.swi-prolog.org/p/PriFIpMa.pl</a>

Live Demo of Version 34 at <a href='https://swish.swi-prolog.org/p/NOdHjmYT.pl'>https://swish.swi-prolog.org/p/NOdHjmYT.pl</a>

Live Demo of Version 35 at <a href='https://swish.swi-prolog.org/p/KpjrGnSM.pl'>https://swish.swi-prolog.org/p/KpjrGnSM.pl</a>

Live Demo of Version 36 at <a href='https://swish.swi-prolog.org/p/FFoGarob.pl'>https://swish.swi-prolog.org/p/FFoGarob.pl</a>

Live Demo of Version 37 at <a href='https://swish.swi-prolog.org/p/MwbaGcrC.pl'>https://swish.swi-prolog.org/p/MwbaGcrC.pl</a>

Live Demo of Version 38 at <a href='https://swish.swi-prolog.org/p/oEjzQpQS.pl'>https://swish.swi-prolog.org/p/oEjzQpQS.pl</a>

Live Demo of Version 39 at <a href='https://swish.swi-prolog.org/p/uUeStUuu.pl'>https://swish.swi-prolog.org/p/uUeStUuu.pl</a>

Live Demo of Version 40 at <a href='https://swish.swi-prolog.org/p/QalMHBwy.pl'>https://swish.swi-prolog.org/p/QalMHBwy.pl</a>

Live Demo of Version 41 at <a href='https://swish.swi-prolog.org/p/HEeUcHvO.pl'>https://swish.swi-prolog.org/p/HEeUcHvO.pl</a>

Live Demo of Version 42 at <a href='https://swish.swi-prolog.org/p/ZVwRDvkA.pl'>https://swish.swi-prolog.org/p/ZVwRDvkA.pl</a>

Live Demo of Version 43 at <a href='https://swish.swi-prolog.org/p/buEsDHKT.pl'>https://swish.swi-prolog.org/p/buEsDHKT.pl</a>

Live Demo of Version 44 at <a href='https://swish.swi-prolog.org/p/TBZTJzkl.pl'>https://swish.swi-prolog.org/p/TBZTJzkl.pl</a>

Live Demo of Version 45 at <a href='https://swish.swi-prolog.org/p/mfHlmCBV.pl'>https://swish.swi-prolog.org/p/mfHlmCBV.pl</a>

Live Demo of Version 46 at <a href='https://swish.swi-prolog.org/p/MwwhoPQQ.pl'>https://swish.swi-prolog.org/p/MwwhoPQQ.pl</a>

Live Demo of Version 47 at <a href='https://swish.swi-prolog.org/p/qSYABUhP.pl'>https://swish.swi-prolog.org/p/qSYABUhP.pl</a>

## Leibniz

<code>Leibniz</code> is a Rule System for expression simplification written in Prolog. <code>Leibniz</code> is named after Gottfried Wilhelm Leibniz (one of the inventors of Calculus) whose notation for his calculus was algebraic.

Historically, applying the rules of algebra strictly to problems in calculus has led to contradictions.

Consider the relatively simple (h/h)@h=0. We may proceed with [h/h@h=0] = [1@h=0] = 1. Alternatively, we may proceed with [h/h@h=0] = [h@h=0]/[h@h=0] = 0/0. The same rules applied in different orders yield different results.

Consider a calculation of the slope of the tangent line of the function f(x)=x^2. We may try to find that slope by simplifying the expression (f(x+h)-f(x))/h @h=0. The part @h=0 means evaluate at h=0. Proceeding with our calculation, [(f(x+h)-f(x))/h @ h=0 ] = [((x+h)^2-x^2)/h @ h=0 ] = [(x^2+2xh+h^2-x^2)/h @ h=0 ] = [(2xh+h^2)/h @ h=0 ] = [2x+h @ h=0 ] = 2x+0 = 2x. We correctly found that the slope of the tangent line is 2x. Let's try applying the same rules again but in a different order. [(f(x+h)-f(x))/h @ h=0 ] = (f(x+0)-f(x))/0 = (f(x)-f(x))/0 = 0/0. Since two different answers were obtained with the same system of rules, the system was considered to be bad (not well defined). This apparent problem was dispensed with by disallowing division by zero (in any and all forms). So, (f(x+h)-f(x))/h @ h=0 was said to be undefined. The above short calculation of the slope of the tangent line yielding 2x was labeled an invalid derivation.

This bares a striking resemblance to parse trees for Context Free Grammars. You start with an expression. You apply some transformation rules to the expression. You get a new expression. However, in parse trees each node can be either a terminal or a non-terminal node. If a node is a terminal node then you can terminate and return that node as the parsed value of the original. If a node is a non-terminal node then you cannot terminate and return that node as the parsed value of the original, but you can transform that node using the transformation rules.

We may use a parse tree approach to parse algebraic expressions. Instead of returning 0/0 as a terminal node, we return it as a non-terminal node. This has the same effect as not returning it at all. This results in backtracking that branch of the tree to continue to search for the answer in other parts of the tree. In simplifying h/h@h=0, we avoid returning 0/0, and end up returning 1. Similarly, in simplifying (f(x+h)-f(x))/h @ h=0, we do not return 0/0, and end up returning 2x (literally 2\*x).

<pre>
  			(h@h=0)/(h@h=0)	---	0/0
  		  /
  h/h@h=0
  		  \
  			1@h=0	---		1
</pre>

This is reminiscent of L'Hopital's rule. Yet with L'Hopital's rule, you still employ all the rigmarole of Calculus.

To be clear, it should be stated that <code>Leibniz</code> is not a Calculus system. It is an algebra system. It simply does the algebra so well that it can answer questions which would otherwise require a needlessly complex workaround like Calculus.

One way to think about where this advantage is coming from is in terms of the properties of the transformation rules. The transformation rules of algebra as they are ordinarily cast, as well as our transformation rules, are transitive ( A transformsto B and B transformsto C implies A transformsto C ). However, in addition, the transformation rules of algebra as they are ordinarily cast, are symmetric transformation rules ( A transformsto B implies B transformsto A ) and reflexive ( A transformsto A ). So the transformsto relation for the rules of algebra as they are ordinarily cast, satisfies all the requirements of an equivalence relation. So, if A transforms to B we can just write A = B. This creates the problem. 1 = 0/0 = 0 implies 0 = 1. By not having symmetry, we avoid that problem 1 → 0/0 and 0 → 0/0 but there's nothing that 0/0 transformto. So, we never get 0 → 1 or 1 → 0 or 0=1.

To expand on this, we might consider the problem of simplifying 0/0. If 0/0 is a non-terminal, and the replacement rules can never transform it into a terminal node, then we would have an expression that cannot be parsed into anything (including itself). One solution is to allow 0/0 as a terminal. This might obscure other solutions if there are any so instead of returning the first terminal we could return the list of all terminals. In the case of parsing 0/0 we get the list [0/0]. In case of parsing h/h@h=0 we get the list [0/0,1]. As the parse order always tries to evaluate @ first the 0/0 will always be the earlier solution. We can return the last solution as the canonical solution. So, 0/0 parses to 0/0, and h/h@h=0 parses to 1.

Furthermore, if we are always going to return the canonical solution, we might as well save time and calculate a smaller parse tree. When calculating h/h@h=0, we might as well always simplify the expression to the left of the @ symbol first (in this case h/h simplifies to 1) then apply the @h=0 (in this case 1@h=0) to get the answer (in this case 1). This way we only return 0/0 when required (for example, if the input were literally 0/0, or if the input were something like 0/0@h=0).

## Semantics

One way to think about the comparison between <code>Leibniz</code> and other approaches, is in terms of semantics. The term semantics is popular in the field of logic. To logicians, the term semantics is intended to mean something like the everyday word meaning. However, logicians' definition seems somewhat forced, and alternative interpretations seem needed. Nevertheless, the word can be used to refer to a practical distinction in logic. Sentences have two things about them that can be studied. One is their syntax. This is like the way the symbols are arranged in the sentence, and relates to the rules of arranging such symbols. The second is their semantics. This is the so-called meaning of the sentence. As an example, one can imagine the same sequence of symbols having one meaning in one language, and a different meaning in another language. This is the practical distinction that I want now.

### Extensional Semantics

Consider x+x=2x. What this means depends on the semantics. The normal semantics is that it means that no matter what you substitute in for x, the equation is still true. This semantics defers algebraic truths to arithmetic truths.

Consider x/x=1. What this means depends on the semantics. The normal semantics is that it means that no matter what you substitute in for x, the equation is still true. Under that semantics you try many numbers and it works. However, if you try 0 then you get 0/0=1. This is not unambiguously true in normal arithmetic. Therefore, x/x=1 is not unambiguously true in normal algebra.

### Non-Extensional Semantics

We introduce a new class of semantics. This semantic class does not defer to arithmetic for its meaning. The meaning of this class is directly grounded in generic quantities. Consider x+x=2x. This statement is true because when a thing is added to itself, there are 2 of that thing. So, x+x=2x is true. That is the argument. Arithmetic is not used to confirm the statement, because that is not the intention of this new semantic class. Consider x/x=1. How many quantities per quantity are there? The answer is 1. Hence, x/x=1. This statement is judged to be true.

This semantic class seems to have a corresponding visual interpretation:

<pre>
           ▄█
         ▄▀ █ x
       ▄▀   █
     ▄█▄▄▄▄▄█
         x
</pre>

If we consider how many steps we rise for each step we move to the right, then the answer is 1. Hence, x/x=1. The slope is considered to be 1.

Similarly:

<pre>
            █
           ██
          █ █
         █  █
        █   █ 2x
       █    █
      █     █
     ████████
         x
</pre>

If we consider how many steps up we rise, for each step we move to the right, then the answer is 2. Hence, 2x/x=2. The slope is considered to be 2.

Normally, x stands in for a particular number or rather any particular number. We verify that an algebraic equation is true by verifying that the equation holds after particular numbers are substituted for x. This kind of x is usually referred to as a variable. The name variable is intended to signify that it is not one particular number.

Our meaning of x is not identical to that of a variable. x is not intended to vary over different particular numbers, which may be substituted for x. x is intended to be a quantity. It is not a particular quantity. It is a general quantity. It is a generic quantity. We merely think about what would be true for a generic quantity.

This suggests that we may escape the degeneracy that happens in normal algebra where a square, and a right triangle of same length are the same thing if the length is zero. For example, ordinarily [½x²/x² @ x=0] = 0/0 undefined. For us [½x²/x² @ x=0] = ½. Triangles are triangles, no matter their size. Same for squares. Their ratio is always ½. For them, some triangles are so small they lose their identity and become a point.

The semantics of arithmetic is something of a foundation. The semantics of normal algebra is grounded in that foundation. As such, normal algebra struggles in the same places where arithmetic struggles. For example, they both struggle with ratios of small quantities. Fortunately, algebra need not be grounded in arithmetic. We have provided an alternate semantics for algebra. It is robust to ratios of small quantities. Other systems may use this semantics as their foundation. We may turn the tables and ground arithmetic in algebra. We may also ground calculus in algebra.

One reason to think that we may have gotten it backwards is by thinking about number and quantity. Numbers are things like 5 or 7. Numbers are particular quantities. In normal algebra, we have variables. We think of them as varying over different numbers. Variables vary over particular quantities. The notion of not being a particular quantity is constructed as varying over particular quantities. This does not quite capture the notion of not being particular. This construction leads to confusions about things like x/x. Instead, we may think of a generic quantity. This generic quantity is not standing in for particular quantities. Generic quantities are not generic particular quantities. The particularity fails to help, and helps to fail. The generic quantity is just that: a quantity. It may have a name, like x. However, this does not make it particular. Furthermore, the rules of how to manipulate quantities that are not particular, is not constrained by the rules of how to manipulate quantities that are particular.

In the alternative, rather than changing the semantics of algebra, we can change the semantics of arithmetic. Earlier, we spoke about parsing x/x@x=0. We can parse it  as (x@x=0)/(x@x=0) then 0/0. We can parse it as 1@x=0 then 1. In this 2 branch tree we avoid the 0/0 branch to get 1. We formalized this at one point with directional parses → instead of bidirectional =. We could try fixing arithmetic this way then basing algebra on it. 1 → 0/0 and 0 → 0/0 but not 0/0 → something. Perhaps, it is not entirely important if we fix algebra, and then base arithmetic on the fixed algebra, or if we fix arithmetic and base algebra on the new arithmetic. It is important that we fix. We could also fix both and merely have them compatible, and perhaps interderivable without the need of declaring one as the foundation.

## Transcendental

Transcendentals transcend polynomials. exp(x) = 1 + h + h^2/2 + … . It is the … that makes it transcendental. Attempting to compute with this transcendent object can be daunting. I may want to simplify (exp(h)–1)/h@h=0 = (1 + h + h^2/2 + … – 1)/h@h=0 = (h + h^2/2 + …)/h@h=0 = (1 + h/2 + …)@h=0 = 1 . Getting the computer to allow computation with … can be challenging. One satisfying resolution is to try partial sums until it works. (exp(h)–1)/h@h=0 = (1 – 1)/h@h=0 = 0/h@h=0 = 0/0 . Retry. (exp(h)–1)/h@h=0 = (1 + h – 1)/h@h=0 = h/h@h=0 = 1@h=0 = 1 . Success. This is not unlike, and somehow identical to L'Hopital's rule. First try Limit of 0ᵗʰ Derivative of Numerator & Denominator (1–1)/0 = 0/0. Retry. Limit of 1ˢᵗ Derivative of Numerator & Denominator 1/1 = 1. Success. The resemblance to L'Hopital's rule is eerie.

To be absolutely safe, in place of the … we may be better off keeping around an error term (like O(h^2)). That way we can make sure that the error term is small compared to a possible divisor, or Retry when it's not.

If for some reason you are partial to Calculus you may model the Algebraic approach using Calculus. If for some reason you are partial to Algebra you may model the Calculus approach using Algebra. If you are impartial you may intermodel. One benefit of having the Algebra as the base is that Algebra is simpler and easier to understand, and Occam's razor may prefer the simpler model, if you are partial to simple models.

## Functions

### Evaluation

In Algebra textbooks, we often see expressions like x * h|ₓ₌₂.  This is read "x\*h evaluated at x=2".  This means take the expression x\*h, and everywhere you see an x replace it with 2.  <code>Leibniz</code> supports evaluating expressions.  However, the syntax is slightly different.  Instead of writing the subscript ₓ₌₂, <code>Leibniz</code> uses the non-subscript x=2.  Also instead of the pipe symbol |, <code>Leibniz</code> uses the at symbol @.  For example, <code>Leibniz</code> supports the expression x\*h@x=2.

### Order of Operations

How should we group the parts of "x\*h evaluated at x=2"? Grouping like "(x\*h) evaluated at (x=2)" has some merits.  One is that the left is an expression, and the right is a substitution.  This can be framed in terms of order of operations.  In x\*h|ₓ₌₂ what operator has the highest precedence?  If following the previous suggestion then it is |.

### Functions

<code>Leibniz</code> has adopted a new order of operations, specifically to accommodate functions, in as natural a way as possible. Instead of having @ as the highest priority, = is given the highest priority. Instead of x\*h@x=2 being parenthesized like (x\*h)@(x=2), it is parenthesized like (x\*h@x)=2.  This may look odd.  (x\*h)@(x=2) looks like "(x\*h) evaluated at (x=2)". (x\*h@x)=2 looks like "(x\*h evaluated at x) equals 2". Seemingly nonsensical. However, in the expression x\*h|ₓ₌₂ the = was never really an equal (e.g. it was never symmetric). A better reading may be "x\*h substitute x with 2". So, | is substitute. The = is with. So, (x\*h)@(x=2) means "(x\*h) substitute (x with 2)". While (x\*h@x)=2 should read "(x\*h substitute x) with 2".  This is at least a minor improvement.  It looks somewhat like a partial application.  The "x\*h substitute x" does seem to leave something hanging (like the other shoe to drop).  This may be seen as the nature of a function.  A function is a reification of part of a computation.  In x\*h@x=2, the x\*h@x is a function.  This is not dissimilar to the relatively familiar arrow notation (e.g. C++'s => or Java's ->) for a function.  A notation like x↦x\*h means a function with argument x and returns x\*h.  We could easily imagine a backward arrow x\*h↤x means a function with argument x and returns x\*h.  <code>Leibniz</code>'s @ is like ↤.

We may reuse functions by assigning (unifying) them to a Prolog variable (notated using capital letters).  Then later we may use that variable anywhere that we want that function.  Some care need be taken. In making an assignment (really a unification) Prolog uses the = symbol.  In this context, the = is a predicate (something that is true or false).  We also use the = symbol inside an expression.  In this context the = symbol is a functor.  A danger is that incorrect usage, instead of throwing an error message, may result in a functor being interpreted as a predicate, or vice-versa.  This can lead to silent logic errors that are hard to debug.  This is not unlike assignment expressions in c, where if we write "if (x=0)" instead of "if (x==0)" then we get no warning, because in c "x=0" is somewhat unintuitively also an expression.  In the future, to avoid these kinds of problems, we may want to change <code>Leibniz</code>'s syntax.  Instead of writing x\*h@x=2, we may prefer x*h@x←2 or similar.

In the spirit of purism, we also have the option of reusable functions, without relying additional language features (like Prolog variables).  How?  Well, with functions we already have the facility of replacement.  Instead of rewriting the same function in multiple places in the same expression, we may instead write a generic there.  Then we evaluate the entire expression substituting the generic with a function.  This way we only write the function once.  And we didn't have to rely on any new language features to support this.

## Constraints

<code>Leibniz</code> allows for expressions like x/2@x=6 .  We might read this in words as x/2 at x=6.  The answer should be 3.  Alternatively, we may read this as the function x/2↤x apply 6 .  Again the answer is 3 .  Let us explore the function x/2↤x in more detail.  First we will write it in the more common left to right way x↦x/2 .  This maps (or transforms) x to x/2 .

Now consider a new syntax : 2\*x↦x .  That transforms (or maps) 2\*x to x .  This seems to have the same effect as x↦x/2 .  The input is reduced by a factor of 2 .  One difference may be that in the first case x↦x/2 may be achieved directly through substitution of x, while 2\*x↦x seems implicit and seems to require more than substitutional semantics .  One way to look at this is that it actually is beyond substitutional semantics .  Another way to look at it is that / is just implicit reverse * anyway , so that / was already implicit and beyond substitutional semantics .  One possible resolution is that common implicit reversals become known operations like / .

Allowing for notation like 2\*x↦x invites x↤2\*x .  Using <code>Leibniz</code>'s @ symbol would be x@2\*x .  By allowing <code>Leibniz</code> to use such (backward) expressions , we can further write x@2\*x=6 .  We may read this as x at 2\*x=6 .  Under that reading the problem is a constraint.  With this minor generalization of syntax , <code>Leibniz</code> can now solve constraints .
